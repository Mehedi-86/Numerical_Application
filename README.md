<h1>ğŸ“Œ Numerical Methods in C++</h1>

<p>This project implements various <b>Numerical Methods</b> using C++. The implemented methods include:</p>
<ul>
  <li><b>Jacobi Iterative Method</b></li>
  <li><b>Gauss-Seidel Iterative Method</b></li>
  <li><b>Gauss Elimination Method</b></li>
  <li><b>Gauss-Jordan Elimination</b></li>
  <li><b>LU Factorization</b></li>
  <li><b>Root Finding Methods</b> (Bi-section, False Position, Secant, Newton-Raphson)</li>
  <li><b>Runge-Kutta Method</b> (Solving Differential Equations)</li>
  <li><b>Matrix Inversion</b></li>
</ul>

<hr>

<h2>ğŸ“‚ File Structure</h2>
<pre>
ğŸ“ Numerical_Methods/
â”‚â”€â”€ ğŸ“„ main.cpp        # Main entry point
â”‚â”€â”€ ğŸ“„ 2107100.hpp     # Header file 1
â”‚â”€â”€ ğŸ“„ 2107086.hpp     # Header file 2
â”‚â”€â”€ ğŸ“„ 2107102.hpp     # Header file 3
â”‚â”€â”€ ğŸ“„ README.md       # Documentation
</pre>

<hr>

<h2>ğŸš€ How to Run the Program</h2>

<h3>ğŸ”¹ Prerequisites</h3>
<ul>
  <li>A C++ compiler (g++ recommended)</li>
  <li>Basic understanding of numerical methods</li>
</ul>

<h3>ğŸ”¹ Compilation Steps</h3>
<ol>
  <li>Open a terminal and navigate to the project directory: <br>
      <code>cd path/to/Numerical_Methods</code></li>
  <li>Compile the program: <br>
      <code>g++ -o numerical_methods main.cpp -std=c++11</code></li>
  <li>Run the compiled program: <br>
      <code>./numerical_methods</code></li>
</ol>

<hr>

<h2 id="jacobi">ğŸ”¹ Jacobi Iterative Method</h2>

The **Jacobi Method** is an **iterative algorithm** used to solve systems of **linear equations**. It starts with an initial guess and iteratively updates the solution using:

\[
x_i^{(k+1)} = \frac{b_i - \sum_{j \neq i} a_{ij} x_j^{(k)}}{a_{ii}}
\]

âœ… **Advantages**:
- Works well for **diagonally dominant matrices**.
- **Parallelizable**, as updates donâ€™t depend on previous iterations.

âŒ **Disadvantages**:
- **Slow convergence** for large matrices.
- Might **not converge** if the matrix is not diagonally dominant.

---

<h2 id="gauss-seidel">ğŸ”¹ Gauss-Seidel Iterative Method</h2>

An **improvement** over the Jacobi method. It updates each variable **immediately**, using the latest computed values:

\[
x_i^{(k+1)} = \frac{b_i - \sum_{j < i} a_{ij} x_j^{(k+1)} - \sum_{j > i} a_{ij} x_j^{(k)}}{a_{ii}}
\]

âœ… **Advantages**:
- **Faster convergence** than Jacobi.
- Uses **previously updated values**, improving accuracy.

âŒ **Disadvantages**:
- **Sequential**, so harder to parallelize.
- Might not converge for **non-diagonally dominant** matrices.

---

<h2 id="gauss-elimination">ğŸ”¹ Gauss Elimination Method</h2>

A **direct method** that systematically eliminates variables to solve linear equations using row operations.

### Steps:
1ï¸âƒ£ Convert the system into **Upper Triangular Form**.  
2ï¸âƒ£ Perform **back-substitution** to get the solution.

âœ… **Advantages**:
- Efficient for **small to medium-sized** systems.
- Works for **any square system**.

âŒ **Disadvantages**:
- Computationally expensive **\(O(n^3)\)** for large matrices.
- Prone to **numerical instability**.

---

<h2 id="gauss-jordan">ğŸ”¹ Gauss-Jordan Elimination</h2>

An **extension of Gauss Elimination**, where the system is transformed into **Reduced Row Echelon Form (RREF)**.

### Steps:
1ï¸âƒ£ Convert the matrix into an **identity matrix**.  
2ï¸âƒ£ The remaining matrix contains the solution.

âœ… **Advantages**:
- Finds **exact solution** directly.
- Can be used for **matrix inversion**.

âŒ **Disadvantages**:
- **More computationally expensive** than Gauss Elimination.
- **Not practical** for very large systems.

---

<h2 id="lu-factorization">ğŸ”¹ LU Factorization</h2>

Decomposes a matrix **A** into **lower (L) and upper (U) triangular matrices**, where:

\[
A = LU
\]

### Steps:
1ï¸âƒ£ Solve **Ly = b** using forward substitution.  
2ï¸âƒ£ Solve **Ux = y** using back substitution.

âœ… **Advantages**:
- Efficient for **multiple linear systems** with the same **A** but different **b**.
- Reduces computational complexity.

âŒ **Disadvantages**:
- Requires **matrix decomposition**, which adds overhead.
- Not always stable for **ill-conditioned matrices**.

---

<h2 id="root-finding">ğŸ”¹ Root Finding Methods</h2>

Finding the **roots of a function \( f(x) = 0 \)** is essential in numerical methods.

### 1ï¸âƒ£ Bi-Section Method
- **Bracket-based method**: Requires two points where **\( f(a) \cdot f(b) < 0 \)**.
- Repeatedly **halves the interval** until the root is found.

âœ… **Always converges**, but **slow**.

### 2ï¸âƒ£ False Position (Regula Falsi)
- Uses **linear interpolation** to approximate the root.

âœ… **Faster than Bi-section**, but may converge **slowly for some functions**.

### 3ï¸âƒ£ Secant Method
- Uses **two previous points** to approximate the derivative.

âœ… **No need for derivative calculations**.

### 4ï¸âƒ£ Newton-Raphson Method
- Uses the **first derivative** to iteratively refine the root:

\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
\]

âœ… **Fast convergence** for well-behaved functions.

âŒ **Fails for non-differentiable functions**.

---

<h2 id="runge-kutta">ğŸ”¹ Runge-Kutta Method (Solving Differential Equations)</h2>

A powerful method for solving **Ordinary Differential Equations (ODEs)** of the form:

\[
\frac{dy}{dx} = f(x, y)
\]

**4th Order Runge-Kutta** uses:

\[
y_{n+1} = y_n + \frac{h}{6} (k_1 + 2k_2 + 2k_3 + k_4)
\]

where:

\[
k_1 = h f(x_n, y_n)
\]
\[
k_2 = h f(x_n + h/2, y_n + k_1/2)
\]
\[
k_3 = h f(x_n + h/2, y_n + k_2/2)
\]
\[
k_4 = h f(x_n + h, y_n + k_3)
\]

âœ… **More accurate** than **Eulerâ€™s Method**.  
âœ… Suitable for **non-linear** ODEs.  

âŒ **Computationally expensive**.

---

<h2 id="matrix-inversion">ğŸ”¹ Matrix Inversion</h2>

Used to find the **inverse of a matrix** \( A^{-1} \), such that:

\[
A A^{-1} = I
\]

**Using Gauss-Jordan Method**:
1ï¸âƒ£ Append **identity matrix** to \( A \).  
2ï¸âƒ£ Perform **row operations** to convert \( A \) into **identity matrix**.  
3ï¸âƒ£ The result is \( A^{-1} \).

âœ… **Used for solving simultaneous equations**.

âŒ **Computationally expensive for large matrices**.

---

## ğŸ“œ Summary

These **numerical methods** are widely used in **engineering and science** for solving complex equations efficiently. 

If you have any **suggestions or contributions**, feel free to **fork this project and create a pull request! ğŸš€**

---

## ğŸ“ References:
ğŸ“Œ Numerical Methods in Engineering  
ğŸ“Œ Applied Mathematics Textbooks  

---
<h2>ğŸ“œ License</h2>
<p>This project is open-source. Feel free to modify, share, and contribute!</p>

<h2>ğŸš€ Happy Coding! ğŸ˜Š</h2>
